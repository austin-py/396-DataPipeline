{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "first_df=pd.read_csv('Arrests_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "r = requests.get('https://data.cityofchicago.org/resource/crimes.json?$limit=600000')\n",
    "data = r.json()\n",
    "sec_df = pd.DataFrame(data)\n",
    "sec_df = sec_df[['case_number','ward','district']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68416\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>case_number</th>\n",
       "      <th>date_month</th>\n",
       "      <th>date_day</th>\n",
       "      <th>date_year</th>\n",
       "      <th>time</th>\n",
       "      <th>meridiem</th>\n",
       "      <th>race</th>\n",
       "      <th>charge_1_statute</th>\n",
       "      <th>charge_1_description</th>\n",
       "      <th>...</th>\n",
       "      <th>charge_4_statute</th>\n",
       "      <th>charge_4_description</th>\n",
       "      <th>charge_4_type</th>\n",
       "      <th>charge_4_class</th>\n",
       "      <th>CHARGES STATUTE</th>\n",
       "      <th>CHARGES DESCRIPTION</th>\n",
       "      <th>CHARGES TYPE</th>\n",
       "      <th>CHARGES CLASS</th>\n",
       "      <th>ward</th>\n",
       "      <th>district</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30039812</td>\n",
       "      <td>JE183770</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>2021</td>\n",
       "      <td>12:10:00</td>\n",
       "      <td>AM</td>\n",
       "      <td>WHITE HISPANIC</td>\n",
       "      <td>720 ILCS 5.0/12-3.2-A-1</td>\n",
       "      <td>DOMESTIC BATTERY - BODILY HARM</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>720 ILCS 5.0/12-3.2-A-1 |  |  |</td>\n",
       "      <td>DOMESTIC BATTERY - BODILY HARM |  |  |</td>\n",
       "      <td>M |  |  |</td>\n",
       "      <td>A |  |  |</td>\n",
       "      <td>14</td>\n",
       "      <td>008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id case_number  date_month  date_day  date_year      time meridiem  \\\n",
       "0  30039812    JE183770           3        30       2021  12:10:00       AM   \n",
       "\n",
       "             race         charge_1_statute            charge_1_description  \\\n",
       "0  WHITE HISPANIC  720 ILCS 5.0/12-3.2-A-1  DOMESTIC BATTERY - BODILY HARM   \n",
       "\n",
       "   ... charge_4_statute charge_4_description charge_4_type charge_4_class  \\\n",
       "0  ...              NaN                  NaN           NaN            NaN   \n",
       "\n",
       "                   CHARGES STATUTE                     CHARGES DESCRIPTION  \\\n",
       "0  720 ILCS 5.0/12-3.2-A-1 |  |  |  DOMESTIC BATTERY - BODILY HARM |  |  |   \n",
       "\n",
       "  CHARGES TYPE CHARGES CLASS ward district  \n",
       "0    M |  |  |     A |  |  |   14      008  \n",
       "\n",
       "[1 rows x 30 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = pd.merge(first_df, sec_df, on=\"case_number\")\n",
    "print(len(merged_df))\n",
    "merged_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# races = {'BLACK': 1, 'WHITE': 2, 'WHITE HISPANIC': 3, 'BLACK HISPANIC': 4, 'ASIAN / PACIFIC ISLANDER': 5, 'AMER INDIAN / ALASKAN NATIVE': 6, 'UNKNOWN / REFUSED': 7}\n",
    "# merged_df['race'] = merged_df['race'].apply(lambda x: races[x])\n",
    "# merged_df = merged_df[['race','ward','district','date_day','date_year','charge_1_type']].dropna()\n",
    "# merged_df.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race_WHITE HISPANIC</th>\n",
       "      <th>race_BLACK</th>\n",
       "      <th>race_BLACK HISPANIC</th>\n",
       "      <th>race_WHITE</th>\n",
       "      <th>race_ASIAN / PACIFIC ISLANDER</th>\n",
       "      <th>race_AMER INDIAN / ALASKAN NATIVE</th>\n",
       "      <th>race_UNKNOWN / REFUSED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68411</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68412</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68413</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68414</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68415</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68416 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       race_WHITE HISPANIC  race_BLACK  race_BLACK HISPANIC  race_WHITE  \\\n",
       "0                        1           0                    0           0   \n",
       "1                        0           1                    0           0   \n",
       "2                        0           1                    0           0   \n",
       "3                        0           1                    0           0   \n",
       "4                        0           0                    1           0   \n",
       "...                    ...         ...                  ...         ...   \n",
       "68411                    0           0                    1           0   \n",
       "68412                    0           1                    0           0   \n",
       "68413                    0           1                    0           0   \n",
       "68414                    1           0                    0           0   \n",
       "68415                    0           1                    0           0   \n",
       "\n",
       "       race_ASIAN / PACIFIC ISLANDER  race_AMER INDIAN / ALASKAN NATIVE  \\\n",
       "0                                  0                                  0   \n",
       "1                                  0                                  0   \n",
       "2                                  0                                  0   \n",
       "3                                  0                                  0   \n",
       "4                                  0                                  0   \n",
       "...                              ...                                ...   \n",
       "68411                              0                                  0   \n",
       "68412                              0                                  0   \n",
       "68413                              0                                  0   \n",
       "68414                              0                                  0   \n",
       "68415                              0                                  0   \n",
       "\n",
       "       race_UNKNOWN / REFUSED  \n",
       "0                           0  \n",
       "1                           0  \n",
       "2                           0  \n",
       "3                           0  \n",
       "4                           0  \n",
       "...                       ...  \n",
       "68411                       0  \n",
       "68412                       0  \n",
       "68413                       0  \n",
       "68414                       0  \n",
       "68415                       0  \n",
       "\n",
       "[68416 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "races = merged_df.loc[:, \"race\"].unique().tolist()\n",
    "race_dummies = pd.get_dummies(merged_df, columns=[\"race\"])\n",
    "races = [\"race_\"+r for r in races]\n",
    "race_dummies = race_dummies[races]\n",
    "race_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df[['ward','district','date_day','date_year','charge_1_type']]\n",
    "\n",
    "merged_df = pd.concat([merged_df, race_dummies], axis=1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ward</th>\n",
       "      <th>district</th>\n",
       "      <th>date_day</th>\n",
       "      <th>date_year</th>\n",
       "      <th>charge_1_type</th>\n",
       "      <th>race_WHITE HISPANIC</th>\n",
       "      <th>race_BLACK</th>\n",
       "      <th>race_BLACK HISPANIC</th>\n",
       "      <th>race_WHITE</th>\n",
       "      <th>race_ASIAN / PACIFIC ISLANDER</th>\n",
       "      <th>race_AMER INDIAN / ALASKAN NATIVE</th>\n",
       "      <th>race_UNKNOWN / REFUSED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>008</td>\n",
       "      <td>30</td>\n",
       "      <td>2021</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>010</td>\n",
       "      <td>23</td>\n",
       "      <td>2021</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>004</td>\n",
       "      <td>16</td>\n",
       "      <td>2021</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>011</td>\n",
       "      <td>16</td>\n",
       "      <td>2021</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>008</td>\n",
       "      <td>16</td>\n",
       "      <td>2021</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68411</th>\n",
       "      <td>22</td>\n",
       "      <td>010</td>\n",
       "      <td>7</td>\n",
       "      <td>2022</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68412</th>\n",
       "      <td>34</td>\n",
       "      <td>022</td>\n",
       "      <td>7</td>\n",
       "      <td>2022</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68413</th>\n",
       "      <td>9</td>\n",
       "      <td>005</td>\n",
       "      <td>7</td>\n",
       "      <td>2022</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68414</th>\n",
       "      <td>7</td>\n",
       "      <td>003</td>\n",
       "      <td>7</td>\n",
       "      <td>2022</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68415</th>\n",
       "      <td>28</td>\n",
       "      <td>011</td>\n",
       "      <td>7</td>\n",
       "      <td>2022</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68408 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ward district  date_day  date_year charge_1_type  race_WHITE HISPANIC  \\\n",
       "0       14      008        30       2021             M                    1   \n",
       "1       22      010        23       2021             M                    0   \n",
       "2        7      004        16       2021             F                    0   \n",
       "3       24      011        16       2021             F                    0   \n",
       "4       13      008        16       2021             M                    0   \n",
       "...    ...      ...       ...        ...           ...                  ...   \n",
       "68411   22      010         7       2022             F                    0   \n",
       "68412   34      022         7       2022             M                    0   \n",
       "68413    9      005         7       2022             F                    0   \n",
       "68414    7      003         7       2022             F                    1   \n",
       "68415   28      011         7       2022             F                    0   \n",
       "\n",
       "       race_BLACK  race_BLACK HISPANIC  race_WHITE  \\\n",
       "0               0                    0           0   \n",
       "1               1                    0           0   \n",
       "2               1                    0           0   \n",
       "3               1                    0           0   \n",
       "4               0                    1           0   \n",
       "...           ...                  ...         ...   \n",
       "68411           0                    1           0   \n",
       "68412           1                    0           0   \n",
       "68413           1                    0           0   \n",
       "68414           0                    0           0   \n",
       "68415           1                    0           0   \n",
       "\n",
       "       race_ASIAN / PACIFIC ISLANDER  race_AMER INDIAN / ALASKAN NATIVE  \\\n",
       "0                                  0                                  0   \n",
       "1                                  0                                  0   \n",
       "2                                  0                                  0   \n",
       "3                                  0                                  0   \n",
       "4                                  0                                  0   \n",
       "...                              ...                                ...   \n",
       "68411                              0                                  0   \n",
       "68412                              0                                  0   \n",
       "68413                              0                                  0   \n",
       "68414                              0                                  0   \n",
       "68415                              0                                  0   \n",
       "\n",
       "       race_UNKNOWN / REFUSED  \n",
       "0                           0  \n",
       "1                           0  \n",
       "2                           0  \n",
       "3                           0  \n",
       "4                           0  \n",
       "...                       ...  \n",
       "68411                       0  \n",
       "68412                       0  \n",
       "68413                       0  \n",
       "68414                       0  \n",
       "68415                       0  \n",
       "\n",
       "[68408 rows x 12 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = merged_df[['race_WHITE HISPANIC','race_BLACK','race_BLACK HISPANIC','race_WHITE','race_ASIAN / PACIFIC ISLANDER','race_AMER INDIAN / ALASKAN NATIVE', \\\n",
    "    'race_UNKNOWN / REFUSED','ward','district','date_day','date_year']]\n",
    "y = merged_df[['charge_1_type']]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from  sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "params = {'n_neighbors':[i for i in range(3, 10, 2)],'weights':['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size':[i for i in range(20, 40, 5)]}\n",
    "clf = GridSearchCV(knn, params, cv=5)\n",
    "clf.fit(x_train,y_train)\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.568976680639178"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler() score =  0.5657494569152788\n",
      "StandardScaler() score =  0.5675597393193338\n",
      "PCA() score =  0.5698769007965243\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "scalers = [MinMaxScaler(), StandardScaler(), PCA()]\n",
    "for index, scaling in enumerate(scalers):\n",
    "    pipe = make_pipeline(scaling, clf.best_estimator_)\n",
    "    pipe.fit(x_train,y_train)\n",
    "    y_pred = pipe.predict(x_test)\n",
    "    print(scalers[index], \"score = \", accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No scaling score =  0.5669804489500362\n"
     ]
    }
   ],
   "source": [
    "clf.best_estimator_.fit(x_train,y_train)\n",
    "y_pred = clf.best_estimator_.predict(x_test)\n",
    "print(\"No scaling score = \", accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean \n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/mayablumovitz/Desktop/Northwestern_University/Senior_Year/Fall/CS_396_DS/Project/Final Project.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mayablumovitz/Desktop/Northwestern_University/Senior_Year/Fall/CS_396_DS/Project/Final%20Project.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m net_classifier \u001b[39m=\u001b[39m MLPClassifier()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mayablumovitz/Desktop/Northwestern_University/Senior_Year/Fall/CS_396_DS/Project/Final%20Project.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m net_classifier\u001b[39m.\u001b[39mfit(x_train,y_train[\u001b[39m'\u001b[39m\u001b[39mcharge_1_type\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mtolist())\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mayablumovitz/Desktop/Northwestern_University/Senior_Year/Fall/CS_396_DS/Project/Final%20Project.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m classifier_preds \u001b[39m=\u001b[39m net_classifier\u001b[39m.\u001b[39mpredict(x_test)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mayablumovitz/Desktop/Northwestern_University/Senior_Year/Fall/CS_396_DS/Project/Final%20Project.ipynb#X24sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m score \u001b[39m=\u001b[39m net_classifier\u001b[39m.\u001b[39mscore(x_test,y_test)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "net_classifier = MLPClassifier()\n",
    "net_classifier.fit(x_train,y_train['charge_1_type'].tolist())\n",
    "classifier_preds = net_classifier.predict(x_test)\n",
    "score = net_classifier.score(x_test,y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = [MinMaxScaler(), StandardScaler(), PCA()]\n",
    "scores = []\n",
    "for scaling in scalers:\n",
    "    pipe = make_pipeline(scaling, net_classifier)\n",
    "    pipe.fit(x_train,y_train['charge_1_type'].tolist())\n",
    "    scores.append(pipe.score(x_test,y_test))\n",
    "\n",
    "print(\"MinMaxScore =\",scores[0])\n",
    "print(\"StandardScaler =\",scores[1])\n",
    "print(\"PCA =\",scores[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    # 'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "    # 'activation' : ['identity', 'logistic', 'tanh', 'relu'],\n",
    "    # 'alpha' : [0.001, 0.01,0.0001,0.002,0.003],\n",
    "    'learning_rate' : ['constant', 'invscaling', 'adaptive'],\n",
    "    'learning_rate_init' : [0.001,0.002,0.0011,0.0009],\n",
    "    'random_state':[0,100,200,300,400],\n",
    "}\n",
    "\n",
    "search = GridSearchCV(net_classifier,parameters)\n",
    "search.fit(x_train,y_train['charge_1_type'].tolist())\n",
    "\n",
    "best = search.best_estimator_\n",
    "best_score = best.score(x_test,y_test)\n",
    "print(best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for scaling in scalers:\n",
    "    pipe = make_pipeline(scaling, best)\n",
    "    pipe.fit(x_train,y_train['charge_1_type'].tolist())\n",
    "    scores.append(pipe.score(x_test,y_test))\n",
    "\n",
    "print(\"MinMaxScore =\",scores[0])\n",
    "print(\"StandardScaler =\",scores[1])\n",
    "print(\"PCA =\",scores[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a Random Forest classifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_m = RandomForestClassifier(n_estimators = 100,random_state=0)\n",
    "\n",
    "# Training the model on the training dataset\n",
    "# fit function is used to train the model using the training sets as parameters\n",
    "clf_m.fit(x_train, y_train)\n",
    "scores_RF = cross_val_score(clf_m, x_train,y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "#n_estimators max_depth min_samples_leaf min_samples_split max_features\n",
    "parameters = {'max_depth':[i for i in range(6, 17,2)],'min_samples_leaf':[i for i in range(9, 15)]}\n",
    "clf_mCV = GridSearchCV(clf_m, parameters,cv=5)\n",
    "clf_mCV.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [i for i in range(6,17,2)]\n",
    "k1 = clf_mCV.cv_results_['mean_test_score'][3::6]\n",
    "plt.plot(x,k1,'s-',color = 'r')\n",
    "plt.xlabel(\"max_depth\")\n",
    "plt.ylabel(\"mean test score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [i for i in range(11,17)]\n",
    "k1 = clf_mCV.cv_results_['mean_test_score'][13:19]\n",
    "plt.plot(x,k1,'s-',color = 'r')\n",
    "plt.xlabel(\"min_samples_leaf\")\n",
    "plt.ylabel(\"mean test score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_m = RandomForestClassifier(n_estimators = 100,max_depth=10,min_samples_leaf=12,random_state=0)\n",
    "parameters = {'max_features':[i for i in range(4, 9)],'min_samples_split':[i for i in range(33,39)]}\n",
    "clf_mCV = GridSearchCV(clf_m, parameters,cv=5)\n",
    "clf_mCV.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [i for i in range(4, 9)]\n",
    "k1 = clf_mCV.cv_results_['mean_test_score'][3::6]\n",
    "plt.plot(x,k1,'s-',color = 'r')\n",
    "plt.xlabel(\"max_features\")\n",
    "plt.ylabel(\"mean test score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [i for i in range(33,39)]\n",
    "k1 = clf_mCV.cv_results_['mean_test_score'][18:24]\n",
    "plt.plot(x,k1,'s-',color = 'r')\n",
    "plt.xlabel(\"min_samples_split\")\n",
    "plt.ylabel(\"mean test score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_m = RandomForestClassifier(n_estimators = 100,max_depth=10,min_samples_leaf=12,max_features=7,min_samples_split=36)\n",
    "clf_m.fit(x_train, y_train)\n",
    "scores_RF = cross_val_score(clf_m, x_train,y_train, cv=5)\n",
    "scores_RF.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing predictions on the test dataset\n",
    "y_pred_m = clf_m.predict(x_test)\n",
    "\n",
    "# using metrics module for accuracy calculation\n",
    "print(\"ACCURACY OF THE MODEL: \", accuracy_score(y_test, y_pred_m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "xgb_clf_m = XGBClassifier()\n",
    "xgb_clf_m.fit(x_train, y_train)\n",
    "\n",
    "# testing\n",
    "score_m = xgb_clf_m.score(x_test, y_test)\n",
    "print(\"accuracy score: \", score_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = [MinMaxScaler(), StandardScaler(), PCA()]\n",
    "for index, scaling in enumerate(scalers):\n",
    "    pipe = make_pipeline(scaling, XGBClassifier())\n",
    "    pipe.fit(x_train,y_train)\n",
    "    y_pred = pipe.predict(x_test)\n",
    "    print(scalers[index], \"score = \", accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "light_clf = HistGradientBoostingClassifier()\n",
    "light_clf.fit(x_train, y_train)\n",
    "\n",
    "# testing\n",
    "score_light = light_clf.score(x_test, y_test)\n",
    "print(\"accuracy score: \", score_light)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, scaling in enumerate(scalers):\n",
    "    pipe = make_pipeline(scaling, HistGradientBoostingClassifier())\n",
    "    pipe.fit(x_train,y_train)\n",
    "    y_pred = pipe.predict(x_test)\n",
    "    print(scalers[index], \"score = \", accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_params = {\"max_iter\": [100, 150, 200], \"max_leaf_nodes\": [31, None], \"max_depth\": [9, None], \"l2_regularization\": [0, 0.001, 0.1]}\n",
    "hist_clf = HistGradientBoostingClassifier()\n",
    "hist_clf_cv = GridSearchCV(hist_clf, scoring='accuracy', cv=5, param_grid=hist_params)\n",
    "hist_clf_cv.fit(x_train, y_train)\n",
    "print(\"best accuracy: \", hist_clf_cv.best_score_)\n",
    "print(\"best parameters: \", hist_clf_cv.best_params_)\n",
    "print(hist_clf_cv.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "dims = list(range(1, 14))\n",
    "acc_scores = []\n",
    "for dim in dims:\n",
    "    # PCA\n",
    "    pca_project = PCA(n_components=dim)\n",
    "    trans_s_data = pca_project.fit_transform(x_train)\n",
    "\n",
    "    # CV\n",
    "    hist_params = {'l2_regularization': [0.001], 'max_depth': [None], 'max_iter': [100], 'max_leaf_nodes': [31]}\n",
    "    hist_clf = HistGradientBoostingClassifier()\n",
    "    hist_clf_cv = GridSearchCV(hist_clf, scoring='accuracy', cv=5, param_grid=hist_params)\n",
    "    hist_clf_cv.fit(trans_s_data, y_train)\n",
    "    acc_scores.append(hist_clf_cv.best_score_)\n",
    "    print(\"dim = \", dim, \" accuracy score: \", hist_clf_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dims, acc_scores)\n",
    "plt.axvline(x = 4, color = 'purple', label = 'axvline - full height', linestyle=\":\")\n",
    "plt.axvline(x = 12, color = 'purple', label = 'axvline - full height', linestyle=\":\")\n",
    "plt.xlabel(\"dimension\")\n",
    "plt.ylabel(\"accuracy score\")\n",
    "plt.title(\"Explore Reduced Dimensions by Knee Method\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import VotingClassifier, AdaBoostClassifier, RandomForestClassifier, HistGradientBoostingClassifier, StackingClassifier, ExtraTreesClassifier\n",
    "\n",
    "y_bool_train = [i == \"M\" for i in y_train['charge_1_type']]\n",
    "y_bool_test = [i == \"M\" for i in y_test['charge_1_type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_model = DecisionTreeClassifier(criterion='entropy')\n",
    "decision_tree_model.fit(x_train, y_bool_train)\n",
    "y_pred = decision_tree_model.predict(x_test)\n",
    "cv_results = cross_validate(decision_tree_model, x_train, y_bool_train)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_model = DecisionTreeClassifier(criterion='entropy')\n",
    "best_depth = []\n",
    "best_min_samples = []\n",
    "best_nodes = [] \n",
    "\n",
    "for i in range(1,21):\n",
    "    decision_tree_model = DecisionTreeClassifier(criterion='entropy', max_depth = i)\n",
    "    decision_tree_model.fit(x_train, y_bool_train)\n",
    "    y_pred = decision_tree_model.predict(x_train)\n",
    "    cv_results = cross_validate(decision_tree_model, x_train, y_bool_train)\n",
    "    score = np.mean(cv_results['test_score'])\n",
    "    best_min_samples.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(range(20))\n",
    "best_min_samples \n",
    "\n",
    "print(best_min_samples.index(max(best_min_samples)))\n",
    "plt.plot(x, best_min_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20,200,5):\n",
    "    decision_tree_model = DecisionTreeClassifier(criterion='entropy', max_depth = 7, max_leaf_nodes=i)\n",
    "    decision_tree_model.fit(x_train, y_bool_train)\n",
    "    y_pred = decision_tree_model.predict(x_train)\n",
    "    cv_results = cross_validate(decision_tree_model, x_train, y_bool_train)\n",
    "    score = np.mean(cv_results['test_score'])\n",
    "    best_nodes.append(score)\n",
    "print(best_nodes.index(max(best_nodes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_model = DecisionTreeClassifier(criterion='entropy', max_depth = 7, max_leaf_nodes=70)\n",
    "decision_tree_model.fit(x_train, y_bool_train)\n",
    "y_pred = decision_tree_model.predict(x_train)\n",
    "cv_results = cross_validate(decision_tree_model, x_train, y_bool_train)\n",
    "score = np.mean(cv_results['test_score'])\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = BaggingClassifier(base_estimator = DecisionTreeClassifier(criterion='entropy', max_depth = 7,max_leaf_nodes=70))\n",
    "clf.fit(x_train, y_bool_train)\n",
    "cv_results = cross_validate(clf, x_train, y_bool_train)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = []\n",
    "for i in range(10):\n",
    "    clf.append(DecisionTreeClassifier(criterion='entropy', max_depth = 7,max_leaf_nodes=70,max_features='sqrt'))\n",
    "eclf1 = VotingClassifier(estimators=[('clf1', clf[0]), \n",
    "                                     ('clf2', clf[1]), \n",
    "                                     ('clf3', clf[2]), \n",
    "                                     ('clf4', clf[3]), \n",
    "                                     ('clf5', clf[4]), \n",
    "                                     ('clf6', clf[5]), \n",
    "                                     ('clf7', clf[6]), \n",
    "                                     ('clf8', clf[7]), \n",
    "                                     ('clf9', clf[8]), \n",
    "                                     ('clf10', clf[9])], voting='hard')\n",
    "eclf1 = eclf1.fit(x_train, y_bool_train)\n",
    "cv_results = cross_validate(eclf1, x_train, y_bool_train)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aclf = AdaBoostClassifier(base_estimator = DecisionTreeClassifier(criterion='entropy', max_depth = 7,max_leaf_nodes=70,max_features='sqrt'))\n",
    "aclf.fit(x_train,y_bool_train)\n",
    "aclf.score(x_test,y_bool_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rclf = RandomForestClassifier()\n",
    "rclf.fit(x_train,y_bool_train)\n",
    "rclf.score(x_test,y_bool_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eclf = ExtraTreesClassifier()\n",
    "eclf.fit(x_train,y_bool_train)\n",
    "eclf.score(x_test,y_bool_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hclf = HistGradientBoostingClassifier()\n",
    "hclf.fit(x_train,y_bool_train)\n",
    "hclf.score(x_test,y_bool_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('dt', DecisionTreeClassifier(criterion='entropy', max_depth = 7,max_leaf_nodes=70,max_features='sqrt')),('rf',RandomForestClassifier())]\n",
    "sclf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "sclf.fit(x_train,y_bool_train)\n",
    "sclf.score(x_test,y_bool_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "861d1558aefcf33bd47063bd8115b8b386b776d6787af849a7341cedbeb6e451"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
